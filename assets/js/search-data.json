{
  
    
        "post0": {
            "title": "Digit Recognition - using NN and CNN (Pytorch)",
            "content": "Overview . In this post, we will get to grips with neural network. We will use a neural network to classify handwritten digits from MINST dataset. We will then build a CNN and try out the same dataset. Along the way we will learn several concepts such a tensor, activation function and how to use loss function and the selection of hyperparameter such a learning rate and momentum. . Method . We use MINST dataset which is a dataset of handwritten digits black and white images which have been centred, normalised to a standard size of 28 X 28 pixels. . PyTorch is deeplearning framework based on Torch, developed by Facebook. Tensorflow is another such framework developed by Google. Keras a is wrapper framework for Tensorflow with simpler interface more suitable for smaller datasets. for a comparison between these frameworks, read this. . In this blog we will use PyTorch to build our deep learning models. Let&#39;s install the cpu version using: . pip install torch==1.7.1+cpu torchvision==0.8.2+cpu torchaudio===0.7.2 -f https://download.pytorch.org/whl/torch_stable.html . import torch import torchvision from torchvision import datasets, transforms from torch.utils.data import DataLoader from PIL import Image import matplotlib.pyplot as plt from torch import nn, optim from torch.nn import Linear, ReLU, Sequential, Conv2d, MaxPool2d import torch.nn.functional as func . What is a tensor? . Tensor is a n-dimentional array data structure used to store numbers with which mathmematical operations can be performed for machine learning. In Pytorch Tensors are build on GPUs which makes tensor computations such as slicing, mathematical operations extremely efficient. . DataCamp . Input to the neural network in the form of a tensor. Normally images are in the format (H, W, C), these will need to be first converted into a tensor of the format (B, C, H, W) where B = Number of Images (batch) C = number of colour channels (Black and white = 1, colour = 3) H = Height of the image W = Width of the image . # ToTensor converts a numpy image array of (H, W, C) in the range (0, 255) in to a tensor of (C, H, W) in the range (0, 1) # Normalize method accepts mean and std deviation as input. For every channel performs (image - mean)/std. this arranges all the numbers of the channel within the same range and reduces the skews in input data dute to different ranges of numbers. transform_step = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]) # TorchVision.datasets has the most commonly used deep learning datasets available for easy download. All datasets have common interface of tranform. train=True gets the training data (60,000 samples), train=False gets test data (10,00 samples). train_data = datasets.MNIST(root=&#39;./data/mmist_train&#39;, download=True, train=True, transform=transform_step) test_data = datasets.MNIST(root=&#39;./data/minst_test&#39;, download=True, train=False, transform=transform_step) # DataLoader creates a iterable batches of data in order to aid with training a nn model. Setting shuffle to True results in a random suffled batch of images. train_data_loader = DataLoader(train_data, batch_size=32, shuffle=True) test_data_loader = DataLoader(test_data, batch_size=32, shuffle=True) . images, labels = iter(train_data_loader).next() . print(&quot;Before squeeze&quot;, images[0].numpy().shape) print(&quot;After squeeze&quot;, images[0].numpy().squeeze().shape) . plt.figure(figsize=(10,10)) plt.subplot(221), plt.imshow(images[0].numpy().squeeze()); plt.subplot(222), plt.imshow(images[1].numpy().squeeze()); plt.subplot(223), plt.imshow(images[2].numpy().squeeze()); plt.subplot(224), plt.imshow(images[3].numpy().squeeze()); . Deep Neural Network . Deep neural network is a stacked set of nodes with more than one layer between the input and output. Suppose we have a multiple linear regression porblem to solve: . y = a + bx1 + cx2 . where x1 and x2 are the inputs, a is the bias, y is the expected value and b and c are the co-efficients we are trying to learn from the machine learning model. . At the beginning, b and c - also called a weights are assigned random values. The inputs are passed to a node, a bias is assinged which is unrelated to the inputs x1 and x2. The values are combined and passed to an activation function - which decides if the output. The predicted y is then compared with the expected y and the error is calculated. . In a feed-forward netowrk, the error is sent all the way to the initial weights assingment, the weights are adjusted based on the error and it goes for a second round through the network. Every pass through the network continuously improves the result, such that the error reduces with every pass. . Deep neural networks are particularly useful when the input data has a large dimension, the features will need to be learnt but the model (automatic feature extraction) rather than being input - such a image recognition. The lower layers learn the low level features. As it advances through the node stack, each layer learns higher level features based on the output of the previous layer. . Activation Functions . Activation functions decide which of the inputs most influence the model output, they normalize the input to be between (0, 1) or (-1, 1). Three main types are: . Binary Step Function: Given threshold - returns 0 for values below threshold, and 1 for greater than equal to threshold. . Linear Activation Fucntion: Linearly dependent on input. . Non-linear Activation Function: Sigmoid (smooth curve) Hyperbolic (Curve centred around 0) ReLU (Rectified Linear Unit) - similary to linear but has derivative function which helps with back propogation. Leaky ReLU - Has a small positive slope for negative values Parametric ReLU - Softmax - Can give multi-class output, where the value is assigned a probability of belonging to the classes. Used in the final layer of the stack to assign the class. Swish - Self gated activation function . Bias can be considered equivalent to the intercept of a linear equation. It determines the threshold over which a activation function triggers. Weights determine how fast the activation function triggers. . PathMind MissingLink GeeksForGeeks . # 28 * 28 input_size = 784 # First layer has 128 neurons, second layer has 64 neurons hidden_size = [128, 64] # Digits 0 - 9 output_size = 10 # Sequential functions stacks the layers one after another in the order given. LogSoftMax parameter dim=1 is the dimension along which LogSoftMax will be calculated. model = nn.Sequential(nn.Linear(input_size, hidden_size[0]), nn.ReLU(), nn.Linear(hidden_size[0], hidden_size[1]), nn.ReLU(), nn.Linear(hidden_size[1], output_size), nn.LogSoftmax(dim=1)) print(model) . Sequential( (0): Linear(in_features=784, out_features=128, bias=True) (1): ReLU() (2): Linear(in_features=128, out_features=64, bias=True) (3): ReLU() (4): Linear(in_features=64, out_features=10, bias=True) (5): LogSoftmax(dim=1) ) . Why do we use log functions in Machine Learning? . When the input values have high range of values - very small to very high values, we call this range skewed. When performing mathematical operations on the extreme values it will either underflow or overflow when computing. . In maths, log is the inverse function for power. So when dealing with very high or low powered values, we can minimise the effect of the powers by applying log because: . e^a.e^b = e^(a+b) . log(a.b) = log(a) + log(b) . So instead of mutiplying numbers which lead to very big /very low numbers, we dampen the effect of the powers by using log sums. . Feedly . What is a Criterion? . Machine Learning model needs to measure loss after every epoch to so that the weights can be adjusted to reduce this loss for the next epoch. Criterion is the loss function is used to calculate the gradient loss. There are several loss functions: . AbsCriterion (Absolute Error): loss(x,y) = sum(xi - yi)/n MSECriterion (Mean Squared Error): loss(x,y) = (sum(xi - yi)^2)/n NLLLoss (Negative Log Likelihood): loss(y) = -log(y) - summed for all correct classes. Higher the log probability assigned to the right class, more correct the model . GitHub . What is an Optimiser? . Optimiser is an algorithm which adjusts the weights and learning rates of the machine learning model in order to reduce loss. Some of the popular ones are: . Gradient Descent: Calculates derivative of the loss function for the entire dataset before weights can be adjusted. Stochastic Gradient Descent (SGD): Calculates derivative one sample at a time. Minibatch Gradient Descent: Calculates derivative of loss after every batch. Adaptive Moment Estimation (ADAM): Gradual change of velocity based on past gradients. . TowardsDataScience . Parameter vs Hyperparameter . In machine learning, parameters are the co-efficients of the equation we are trying to learn from the model. These are calculated by the model and not given as input to the model. . Hyperparameters are the type of inputs given by the user to train the model such that it achieves the best parameter values. For eg. learning rate, momumtum, number of epochs, batch size, etc. . What is Learning Rate? . Learning rate is a hyperparameter which determines the rate at which the weights are adjusted - value is set between 0 and 1. Ideally, the model must learn the best weights without getting stuck in a local minima but at the same time finding the best possible values with the lowest loss. . Instead of learning rate remaining the same across all epochs they could be made to vary across epochs. Decaying learning rate is one such technique where the learning rate drops steadily as the model advances through the epochs. Scheduled learning rate drops the rate every few epochs. Adaptive learning rate is a technique where the the rate increases and decreases proportional to the value of the gradient descent. . MyGreatLearning . What is Momentum? . In SGD, the loss is determined after every sample. When the sample is noisy, the steps taken to achieve the optimum weights can vary randomly depending on next sample. Momentum is hyperparameter which retains some portion of the learning from the past in taking next step - value between 0 and 1. Momentum is an attempt to smooth the direction of descent, a moving average of gradients which helps avoid local minima and help moving in the direction of the lowest cost for the model without getting stuck in local fluctuations. . https://towardsdatascience.com/stochastic-gradient-descent-with-momentum-a84097641a5d . # Set the criterion = Negative Log Probability. criterion = nn.NLLLoss() # Set the optmiser as Stochastic Gradient Descent with learning rate of 0.001 and momentum of 0.9. optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9) # The number of complete passes of the entire training dataset. epochs = 10 for e in range (epochs): # Loads 32 random images at a time, this is a mini-batch SGD. Multiple passes over the same dataset helps learn the the co-efficients with the lowest cost. for images, labels in train_data_loader: # tensor.view reshapes the view into a new matrix. -1 means calculate this value based on the other values given such that the count matches. [32, 1, 28, 28] changes to [32, 784] images = images.view(images.shape[0], -1) # Start by initializing with 0 gradients for all the parameters. optimizer.zero_grad() # Logsoftmax returns log probabilities - forward pass. log_prob = model(images) # Calculate the loss by comparing the predicted labels with the actual labels using NLL loss. loss = criterion(log_prob, labels) # Computes the loss gradient for each each parameter and stores it - backward pass. loss.backward() # Updates the value of of the co-efficient for all parameters with the corresponding gradient - taking into account learning rate and momentum. optimizer.step() . correct_count = 0 count = 0 for images, labels in test_data_loader: # Pick one image at a time. for i in range(len(labels)): image = images[i].view(1, 784) label = labels[i] # De-activates autograd (gradient calculation). with torch.no_grad(): log_prob = model(image) # Exponential operation is the inverse of log. ps = torch.exp(log_prob) # Convert the tensor into numpy, convert into list. prob = list(ps.numpy()[0]) # Find the index of the list with the highest probablity, the index order is the order of the digits [0-9]. pred_label = prob.index(max(prob)) if (label == pred_label): correct_count += 1 count += 1 . accuracy = (correct_count/count) * 100 print(accuracy) . 96.57 . CNN . Convolutional Neural Network is a variant of neural network which involves a convolutional layer in the stack. CNN is good a reducing the dimentionality of the input without losing the features. Convolutional layer involves applying a kernel function (a matrix of numbers) over the input and adding the values. This extracts the high level features. This is usually followed by a max pooling layer - either max or average pooling where the maximum value of a matrix is taken to the next level - the idea being the noise is left behind and only the key features are extracted. Finally the data is passed on to a fully connected neural network and SoftMax for class prediction. . TowardsDataScience Jeremyjordan . class Net(nn.Module): # Constructor which first calls the base class constructor. def __init__(self): super(Net, self).__init__() self.cnn_layers = Sequential( # in_channels: black and white = 1, colour image = 3, out_channels: number of features to learn, kernel_size = size of the matrix, stride = number of pixels to jump when applying kernel, paddint = number of pixels to add around the image. # conv2d is used of images, conv3d for videos. Conv2d(in_channels=1, out_channels=4, kernel_size=5), # Does the operation in place, can save memory, but original image is lost. ReLU(inplace=True), # Applies max pooling over a matrix of 2 x 2, jumps of 2. MaxPool2d(kernel_size=2), Conv2d(in_channels=4, out_channels=4, kernel_size=5), ReLU(inplace=True), MaxPool2d(kernel_size=2) ) # Final fully connected layer. self.linear_layers = Sequential( # Input and output. Linear(4 * 4 * 4, 10) ) def forward(self, x): x = self.cnn_layers(x) x = x.view(-1, 4 * 4 * 4) x = self.linear_layers(x) return func.log_softmax(x, dim=1) . How is the input and output size calculated? . (inputsize - (filtersize - 1)) . Layer Output size Image . input | 1 x 28 x 28 | 28 x 28 input image size | . conv2d-1 (1, 4, 5) | 4 x 24 x 24 | (28 - (5 - 1)) = 24 | . maxpool2d-1 (2) | 4 x 12 x 12 | 24/2 = 12 | . conv2d-2 (4, 4, 5) | 4 x 8 x 8 | (12 - (5 - 1)) = 8 | . maxpool2d-2 (2) | 4 x 4 x 4 | 8/2 = 4 | . fc1 () | 10 | | . StackOverflow . cnn_model = Net() cnn_model . Net( (cnn_layers): Sequential( (0): Conv2d(1, 4, kernel_size=(5, 5), stride=(1, 1)) (1): ReLU(inplace=True) (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (3): Conv2d(4, 4, kernel_size=(5, 5), stride=(1, 1)) (4): ReLU(inplace=True) (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) ) (linear_layers): Sequential( (0): Linear(in_features=64, out_features=10, bias=True) ) ) . cnn_criterion = nn.NLLLoss() cnn_optimizer = optim.SGD(cnn_model.parameters(), lr=0.001, momentum=0.9) epochs = 10 for e in range (epochs): for images, labels in train_data_loader: # images = images.view(images.shape[0], -1) cnn_optimizer.zero_grad() # Forward. log_prob = cnn_model(images) loss = cnn_criterion(log_prob, labels) # Backward. loss.backward() # Optimize. cnn_optimizer.step() . correct_count = 0 count = 0 for data in test_data_loader: # 32 images and labels. images, labels = data # Get the predictions. # 32 outputs with log probabilities of 10 each for each of the 10 digits. with torch.no_grad(): outputs = cnn_model(images) # torch.max - with dim=1 (column) results in max of the probablilities for each of 32 images. It returns 2 values - max probabliltiy and max index, we are interested in the max index. _, is used to ignore the first set of output. _, predicted = torch.max(outputs.data, 1) # Get the number of images - 32 in each batch except for the last batch. count += labels.size(0) # Get the number of correct guesses in this batch. correct_count += (predicted == labels).sum().item() . accuracy = (correct_count/count) * 100 print(accuracy) . 97.48 . Conclusion . In this example we learnt how to build a simple neural network and CNN. We also found that the performance with a simple neural network was 96.57% while the same data with CNN was 97.48%. In the next blog let us find out how to make CNN more accurate. .",
            "url": "https://avsuja.github.io/ordinary-to-legendary/jupyter/pytorch/neuralnetwork/convolutionalneuralnetwork/2021/01/04/digit-recognition-pytorch.html",
            "relUrl": "/jupyter/pytorch/neuralnetwork/convolutionalneuralnetwork/2021/01/04/digit-recognition-pytorch.html",
            "date": " • Jan 4, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Detect Parkinsons - Using XGBoost Classifier",
            "content": "Overview . XGBoost is perfectly suited to large datasets with numerous features with a mixture of categorical and numerical features for non-deep learning problems. While our dataset is quite small, for the purposes of this example, we will use XGBoost. . XGBoost does not need feature scaling/normalisation as xgboost is a ensemble of decision trees and distance between features are not used in the algorithm (unlike KNN, PCA). . We begin by splitting the dependent(Y) and independent (X) variables. There are 23 independent variables and &quot;Status&quot; is the label, the dependent variable. Then we split the dataset into training and test set. We fit XGBoost model with the training set and test with the test set. . Method . First, let&#39;s download the Parkingsons data set from UCI Machine Learning. . Install xgboost for Python with &quot;pip install xgboost&quot; at command prompt. Test with python &quot;import xgboost&quot; to make sure all is well. . import pandas as pd from sklearn.model_selection import train_test_split from sklearn.metrics import accuracy_score, confusion_matrix import xgboost as xgb . pk_data = pd.read_csv(&quot;. data parkinsons.csv&quot;) . pk_data.shape . (195, 24) . pk_data.head(5) . name MDVP:Fo(Hz) MDVP:Fhi(Hz) MDVP:Flo(Hz) MDVP:Jitter(%) MDVP:Jitter(Abs) MDVP:RAP MDVP:PPQ Jitter:DDP MDVP:Shimmer ... Shimmer:DDA NHR HNR status RPDE DFA spread1 spread2 D2 PPE . 0 phon_R01_S01_1 | 119.992 | 157.302 | 74.997 | 0.00784 | 0.00007 | 0.00370 | 0.00554 | 0.01109 | 0.04374 | ... | 0.06545 | 0.02211 | 21.033 | 1 | 0.414783 | 0.815285 | -4.813031 | 0.266482 | 2.301442 | 0.284654 | . 1 phon_R01_S01_2 | 122.400 | 148.650 | 113.819 | 0.00968 | 0.00008 | 0.00465 | 0.00696 | 0.01394 | 0.06134 | ... | 0.09403 | 0.01929 | 19.085 | 1 | 0.458359 | 0.819521 | -4.075192 | 0.335590 | 2.486855 | 0.368674 | . 2 phon_R01_S01_3 | 116.682 | 131.111 | 111.555 | 0.01050 | 0.00009 | 0.00544 | 0.00781 | 0.01633 | 0.05233 | ... | 0.08270 | 0.01309 | 20.651 | 1 | 0.429895 | 0.825288 | -4.443179 | 0.311173 | 2.342259 | 0.332634 | . 3 phon_R01_S01_4 | 116.676 | 137.871 | 111.366 | 0.00997 | 0.00009 | 0.00502 | 0.00698 | 0.01505 | 0.05492 | ... | 0.08771 | 0.01353 | 20.644 | 1 | 0.434969 | 0.819235 | -4.117501 | 0.334147 | 2.405554 | 0.368975 | . 4 phon_R01_S01_5 | 116.014 | 141.781 | 110.655 | 0.01284 | 0.00011 | 0.00655 | 0.00908 | 0.01966 | 0.06425 | ... | 0.10470 | 0.01767 | 19.649 | 1 | 0.417356 | 0.823484 | -3.747787 | 0.234513 | 2.332180 | 0.410335 | . 5 rows × 24 columns . # pk_data.columns != &#39;status&#39; -&gt; Gives an array of bool values, true for all but status. # .values - converts df into array. x = pk_data.loc[:, pk_data.columns != &#39;status&#39;].values[:, 1:] # loc[row_from: row_to, column_from: column_to] y = pk_data.loc[:,&#39;status&#39;].values . x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 100) . XGBoost . XGB is a progression of Decision Trees. When bagging (taking random samples with replacement from the data) is applied to decision trees it results in Random Forest which is a ensemble of decision trees which results in better accuracy. When boosting (when every tree built aims to correct the errors in the previous tree, additive trees) is added to Random Forest, it result in Boosted Random Tree. When the errors are minimised using Gradient Descent, it results in Gradient Boosting. . XGB added further optimisations to this Gradient Boosted Trees such as parallel processing, tree pruning (to avoid being penalised by regularisation term) along with an efficient missing value imputation and cross-validation. Along with the algorithmic advances the hardware is optimised resulting in significant performance improvements. . XGBoost TowardsDataScience Medium MachineLearningMastery YouTube-GradientBoost YouTube-XGBoost . xgbc = xgb.XGBClassifier() xgbc.fit(x_train, y_train) y_pred = xgbc.predict(x_test) score = accuracy_score(y_test, y_pred) print(&#39;XGB Accuracy: &#39;, round(score * 100, 3)) . [21:21:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective &#39;binary:logistic&#39; was changed from &#39;error&#39; to &#39;logloss&#39;. Explicitly set eval_metric if you&#39;d like to restore the old behavior. XGB Accuracy: 94.872 . Conclusion . Even though the dataset is not massive, XBBoost performed well with 94% accuracy. .",
            "url": "https://avsuja.github.io/ordinary-to-legendary/jupyter/sklearn/xgboost/2021/01/01/parkinsons-xgboost.html",
            "relUrl": "/jupyter/sklearn/xgboost/2021/01/01/parkinsons-xgboost.html",
            "date": " • Jan 1, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Detect Parkinsons - Using XGBoost Classifier",
            "content": "Overview . XGBoost is perfectly suited to large datasets with numerous features with a mixture of categorical and numerical features for non-deep learning problems. While our dataset is quite small, for the purposes of this example, we will use XGBoost. . XGBoost does not need feature scaling/normalisation as xgboost is a ensemble of decision trees and distance between features are not used in the algorithm (unlike KNN, PCA). . We begin by splitting the dependent(Y) and independent (X) variables. There are 23 independent variables and &quot;Status&quot; is the label, the dependent variable. Then we split the dataset into training and test set. We fit XGBoost model with the training set and test with the test set. . Method . First, let&#39;s download the Parkingsons data set from UCI Machine Learning. . Install xgboost for Python with &quot;pip install xgboost&quot; at command prompt. Test with python &quot;import xgboost&quot; to make sure all is well. . import pandas as pd from sklearn.model_selection import train_test_split from sklearn.metrics import accuracy_score, confusion_matrix import xgboost as xgb . pk_data = pd.read_csv(&quot;. data parkinsons.csv&quot;) . pk_data.shape . (195, 24) . pk_data.head(5) . name MDVP:Fo(Hz) MDVP:Fhi(Hz) MDVP:Flo(Hz) MDVP:Jitter(%) MDVP:Jitter(Abs) MDVP:RAP MDVP:PPQ Jitter:DDP MDVP:Shimmer ... Shimmer:DDA NHR HNR status RPDE DFA spread1 spread2 D2 PPE . 0 phon_R01_S01_1 | 119.992 | 157.302 | 74.997 | 0.00784 | 0.00007 | 0.00370 | 0.00554 | 0.01109 | 0.04374 | ... | 0.06545 | 0.02211 | 21.033 | 1 | 0.414783 | 0.815285 | -4.813031 | 0.266482 | 2.301442 | 0.284654 | . 1 phon_R01_S01_2 | 122.400 | 148.650 | 113.819 | 0.00968 | 0.00008 | 0.00465 | 0.00696 | 0.01394 | 0.06134 | ... | 0.09403 | 0.01929 | 19.085 | 1 | 0.458359 | 0.819521 | -4.075192 | 0.335590 | 2.486855 | 0.368674 | . 2 phon_R01_S01_3 | 116.682 | 131.111 | 111.555 | 0.01050 | 0.00009 | 0.00544 | 0.00781 | 0.01633 | 0.05233 | ... | 0.08270 | 0.01309 | 20.651 | 1 | 0.429895 | 0.825288 | -4.443179 | 0.311173 | 2.342259 | 0.332634 | . 3 phon_R01_S01_4 | 116.676 | 137.871 | 111.366 | 0.00997 | 0.00009 | 0.00502 | 0.00698 | 0.01505 | 0.05492 | ... | 0.08771 | 0.01353 | 20.644 | 1 | 0.434969 | 0.819235 | -4.117501 | 0.334147 | 2.405554 | 0.368975 | . 4 phon_R01_S01_5 | 116.014 | 141.781 | 110.655 | 0.01284 | 0.00011 | 0.00655 | 0.00908 | 0.01966 | 0.06425 | ... | 0.10470 | 0.01767 | 19.649 | 1 | 0.417356 | 0.823484 | -3.747787 | 0.234513 | 2.332180 | 0.410335 | . 5 rows × 24 columns . # pk_data.columns != &#39;status&#39; -&gt; Gives an array of bool values, true for all but status. # .values - converts df into array. x = pk_data.loc[:, pk_data.columns != &#39;status&#39;].values[:, 1:] # loc[row_from: row_to, column_from: column_to] y = pk_data.loc[:,&#39;status&#39;].values . x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 100) . XGBoost . XGB is a progression of Decision Trees. When bagging (taking random samples with replacement from the data) is applied to decision trees it results in Random Forest which is a ensemble of decision trees which results in better accuracy. When boosting (when every tree built aims to correct the errors in the previous tree, additive trees) is added to Random Forest, it result in Boosted Random Tree. When the errors are minimised using Gradient Descent, it results in Gradient Boosting. . XGB added further optimisations to this Gradient Boosted Trees such as parallel processing, tree pruning (to avoid being penalised by regularisation term) along with an efficient missing value imputation and cross-validation. Along with the algorithmic advances the hardware is optimised resulting in significant performance improvements. . XGBoost TowardsDataScience Medium MachineLearningMastery YouTube-GradientBoost YouTube-XGBoost . xgbc = xgb.XGBClassifier() xgbc.fit(x_train, y_train) y_pred = xgbc.predict(x_test) score = accuracy_score(y_test, y_pred) print(&#39;XGB Accuracy: &#39;, round(score * 100, 3)) . [21:21:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective &#39;binary:logistic&#39; was changed from &#39;error&#39; to &#39;logloss&#39;. Explicitly set eval_metric if you&#39;d like to restore the old behavior. XGB Accuracy: 94.872 . Conclusion . Even though the dataset is not massive, XBBoost performed well with 94% accuracy. .",
            "url": "https://avsuja.github.io/ordinary-to-legendary/jupyter/sklearn/xgboost/2021/01/01/parkinsons-xgboost-copy.html",
            "relUrl": "/jupyter/sklearn/xgboost/2021/01/01/parkinsons-xgboost-copy.html",
            "date": " • Jan 1, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Detect Fake News - Using a variety of scikit-learn classifiers",
            "content": "Overview . Given a corpus of news documents each labelled as &quot;Real&quot; or &quot;Fake&quot;, the task is to predict the correct label. We will run a variety of ML classifiers to predict the output and compare the accuracy of the classifiers. The input documents will be split into training and test set, transformed to tf-idf vector before feeding them to the classifiers. We will also attempt to understand different concepts and classifiers along the way. . Method . First, let&#39;s download news data set. . import pandas as pd from sklearn.model_selection import train_test_split from sklearn.feature_extraction.text import TfidfVectorizer from sklearn.linear_model import PassiveAggressiveClassifier from sklearn.metrics import accuracy_score, confusion_matrix from sklearn.linear_model import LogisticRegression from sklearn.svm import SVC from sklearn.naive_bayes import MultinomialNB from sklearn.tree import DecisionTreeClassifier from sklearn.ensemble import RandomForestClassifier from sklearn.neural_network import MLPClassifier . news_data = pd.read_csv(&quot;. data news.csv&quot;) . news_data.shape . (6335, 4) . news_data.head(5) . Unnamed: 0 title text label . 0 8476 | You Can Smell Hillary’s Fear | Daniel Greenfield, a Shillman Journalism Fello... | FAKE | . 1 10294 | Watch The Exact Moment Paul Ryan Committed Pol... | Google Pinterest Digg Linkedin Reddit Stumbleu... | FAKE | . 2 3608 | Kerry to go to Paris in gesture of sympathy | U.S. Secretary of State John F. Kerry said Mon... | REAL | . 3 10142 | Bernie supporters on Twitter erupt in anger ag... | — Kaydee King (@KaydeeKing) November 9, 2016 T... | FAKE | . 4 875 | The Battle of New York: Why This Primary Matters | It&#39;s primary day in New York and front-runners... | REAL | . x = news_data[&#39;text&#39;] y = news_data[&#39;label&#39;] . x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 100) . TF-IDF - What is the intuition behind it? . The aim is to convert a document of words into a vector of numbers so it can be fed to ML algorithms. For every word in every document tf-idf is calculated to show the importance of the word in the corpus and the document. . t = term, d = document, N = number of documents in the corpus . Term Frequency: Calculate the frequency of a word in a document. tf (t, d) = count of the word in the document / total number of words in the document . | Document Frequency: Calculate the the number of documents in which the term occurs. df(t) = count of the documents in which term occurs. . | Inverse Document Frequency: Measures the importance of the word in the corpus, relative weight of the term. idf(t) = N/ df(t) - When the corpus is large, the number can be large. idf(t) = log (N/df(t) + 1) - Taking a log dampens this large value, +1 in the denominator is to avoid division by 0. . | Term Frequency-Inverse Document Frequency: tf-idf(t, d) = tf(t, d) * idf(t) . | . MonkeyLearn TowardsDataScience . # stop_words = &#39;english&#39;: Removes all common uninformative words like and, the, etc. # max_df = 0.7 : Removes corpus-specific stop words when the document frequecy is above 0.7. tf_idf_vectorizer = TfidfVectorizer(stop_words = &#39;english&#39;, max_df = 0.7) # fit_transform - Learns the terms and returns a document-term sparce matrix (n_samples, n_features) tf_idf_x_train = tf_idf_vectorizer.fit_transform(x_train) # transform - Returns a document-term sparce matrix (n_samples, n_features) tf_idf_x_test = tf_idf_vectorizer.transform(x_test) . 1. Passive Aggressive Classifier - What is it? . PAC is a streaming algorithm for classifying massive amounts of data. Data is fed to the algorithm in sequestial order. For every example, if the prediction is correct, no change is made to the model (passive), but if the the prediction is incorrect, the model weight is changed to correct the model. The example is thrown away after processing. . This works on the principle of Hinge loss, where if the prediction is correct or overly correct, there is no loss, but if the change is incorrect then there is a loss, bigger the difference, bigger the loss. . The loss is added to the weight vector such that the prediction is just equal to 1. . GeeksForGeeks YouTube MachineCurve . pac = PassiveAggressiveClassifier(max_iter = 50) pac.fit(tf_idf_x_train, y_train) # Predict on the test set. y_pred = pac.predict(tf_idf_x_test) # Calculate the accuracy. score = accuracy_score(y_test, y_pred) print(&quot;PAC Accuracy = &quot;, round((score * 100), 3)) . PAC Accuracy = 93.291 . 2. Logistic Regression Classifier . Logistic regression is like linear regression but with binomial (true/false) results. It predicts the probability of the class using a sigmoid function. . Scikit-Learn YouTube . lr = LogisticRegression(random_state = 100) lr.fit(tf_idf_x_train, y_train) y_pred = lr.predict(tf_idf_x_test) score = accuracy_score(y_test, y_pred) print(&quot;LR Accuracy = &quot;, round((score * 100), 3)) . LR Accuracy = 90.845 . 3. Support Vector Machine . SVM is a supervised ML model which can be used for classification. It does this by finding the best line/plane of separation between the nearest data points from each class. If the classes are not linearly separable in the given dimensions, new dimension is calculated using a kernel function and then a hyperplane is calculated. . MonkeyLearn YouTube . svc = SVC() svc.fit(tf_idf_x_train, y_train) y_pred = svc.predict(tf_idf_x_test) score = accuracy_score(y_test, y_pred) print(&quot;SVC Accuracy = &quot;, round((score * 100), 3)) . LR Accuracy = 50.039 . 4. Naive Bayes Classifier . NB is a probabilistic ML model based on Bayes theorem: . P(y|X) = (P(X|y)p(y))/(P(X)) . Where X = x1, x2...xn (n features), y = expected result. All the predictors are expected to be unrelated (naive assumption) and are considered equally important. . TowardsDataScience YouTube . mnb = MultinomialNB() mnb.fit(tf_idf_x_train, y_train) y_pred = mnb.predict(tf_idf_x_test) score = accuracy_score(y_test, y_pred) print(&quot;MNB Accuracy = &quot;, round((score * 100), 3)) . MNB Accuracy = 85.556 . 5. Decision Tree Classifier . DT is a non-parametric (data does not have well defined distribution) supervised model. This model creates a tree with the given data. When new data is presented, it follows the decision tree to arrive at a class. . YouTube Scikit-Learn . dtc = DecisionTreeClassifier() dtc.fit(tf_idf_x_train, y_train) y_pred = dtc.predict(tf_idf_x_test) score = accuracy_score(y_test, y_pred) print(&quot;DTC Accuracy = &quot;, round((score * 100), 3)) . GNB Accuracy = 80.9 . 6. Random Forest Classifier . This is a ensemble () classifier where several sub-samples of the data (bootstrapping - random sampling of data with replacement) is used to build decision tree classifiers and the result is calculated based on the average of the results from the different trees. . Scikit-Learn YouTube . rfc = RandomForestClassifier() rfc.fit(tf_idf_x_train, y_train) y_pred = rfc.predict(tf_idf_x_test) score = accuracy_score(y_test, y_pred) print(&quot;RFC Accuracy = &quot;, round((score * 100), 3)) . GNB Accuracy = 85.162 . 7. Multilayer Perceptron Classifier . A neural network model based on perceptrons with hidden layers and back propogation. The hidden layers help learn complex patterns int he data and back propogation adjusts the weights of the classifier after every iteration to minimise loss. . Scikit-Learn TowardsDataScience . mlp = MLPClassifier(random_state=100, max_iter=100) mlp.fit(tf_idf_x_train, y_train) y_pred = mlp.predict(tf_idf_x_test) score = accuracy_score(y_test, y_pred) print(&quot;RFC Accuracy = &quot;, round((score * 100), 3)) . RFC Accuracy = 93.212 . Conclusion . Both PassiveAggressiveClassifier and MLPClassifier resulted in 93% accuracy while SVCClassifier produced just 50% accuracy. RandomForestClassifier had a better accuracy (85%) than decision trees(80%). MLP results can probably be improved with hyperparameter tuning. None of the classifiers were tuned for optimal performance and we have not measured the time it takes to train the model. .",
            "url": "https://avsuja.github.io/ordinary-to-legendary/jupyter/sklearn/tfidfvectorizer/passiveaggresiveclassifier/logisticregressionclassifier/supportvectorclassifier/naivebayesclassifier/decisiontreeclassifier/randomforestclassifier/mlpclassifier/2020/12/30/fake-news-detection.html",
            "relUrl": "/jupyter/sklearn/tfidfvectorizer/passiveaggresiveclassifier/logisticregressionclassifier/supportvectorclassifier/naivebayesclassifier/decisiontreeclassifier/randomforestclassifier/mlpclassifier/2020/12/30/fake-news-detection.html",
            "date": " • Dec 30, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "But first...",
            "content": "Aim: To gain confidence in Data Science related topics. . Method: . 1. To build Data Science projects in various topics. 2. To blog about the related topics and the project findings. .",
            "url": "https://avsuja.github.io/ordinary-to-legendary/jupyter/2020/12/30/but-first.html",
            "relUrl": "/jupyter/2020/12/30/but-first.html",
            "date": " • Dec 30, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "Improving CNN (Pytorch)",
            "content": "import torch import torchvision from torchvision import datasets, transforms from torch.utils.data import DataLoader from PIL import Image import matplotlib.pyplot as plt from torch import nn, optim from torch.nn import Linear, ReLU, Sequential, Conv2d, MaxPool2d, Dropout, BatchNorm2d import torch.nn.functional as F . # ToTensor converts a numpy image array of (H, W, C) in the range (0, 255) in to a tensor of (C, H, W) in the range (0, 1) # Normalize method accepts mean and std deviation as input. For every channel performs (image - mean)/std. this arranges all the numbers of the channel within the same range and reduces the skews in input data dute to different ranges of numbers. transform_step = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]) # TorchVision.datasets has the most commonly used deep learning datasets available for easy download. All datasets have common interface of tranform. train=True gets the training data (60,000 samples), train=False gets test data (10,00 samples). train_data = datasets.MNIST(root=&#39;./data/mmist_train&#39;, download=True, train=True, transform=transform_step) test_data = datasets.MNIST(root=&#39;./data/minst_test&#39;, download=True, train=False, transform=transform_step) # DataLoader creates a iterable batches of data in order to aid with training a nn model. Setting shuffle to True results in a random suffled batch of images. train_data_loader = DataLoader(train_data, batch_size=32, shuffle=True) test_data_loader = DataLoader(test_data, batch_size=32, shuffle=True) . What is Regularization? . When a model learns the training data so well that it has not learnt the pattern but instead the data itself, the model tends to not generalize well, i.e. it does not predict the test data well. Regularization is a penalty term added to the error term such that the co-efficients learnt by this model does not fluctuate wildly. . In Neural Networks there are several techniques for applying regularization: . Dropout: This is implemented as a layer where the parameters are dropped randomly with a probablity of retaining the values. This has the effect forcing the model to learn from sparse neurons. Probability of 1 means no dropouts, 0.2 means 0.2 of the the neurons will be dropped. | L1 Regularization (Lasso Regression): This regression is applied such that the the weights are sparse and therefore the model has fewer parameters. Only the important parameters are retained and the co-efficient of less important parameters are reduced to zero, thus learning the general trend of the model. (nn.L1Loss) | L2 Regularization (Ridge Regression): In this the squared magnitude of the cofficient is added to the penalty term, leaving us with a set of simple features that explain the model most, the less important ones have lesser weights. | TowardsDataScience [EddenGerber] (https://medium.com/@edden.gerber/thanks-for-the-article-1003ad7478b2) MachineLearningMastery . class Net_d(nn.Module): # Constructor which first calls the base class constructor. def __init__(self): super(Net_d, self).__init__() self.cnn_layers = Sequential( Conv2d(in_channels=1, out_channels=4, kernel_size=5), ReLU(), MaxPool2d(kernel_size=2), Dropout(p=0.5), Conv2d(in_channels=4, out_channels=4, kernel_size=5), ReLU(), MaxPool2d(kernel_size=2), Dropout(p=0.5) ) # Final fully connected layer. self.linear_layers = Sequential( # Input and output. Linear(4 * 4 * 4, 10) ) def forward(self, x): x = self.cnn_layers(x) x = x.view(-1, 4 * 4 * 4) x = self.linear_layers(x) return F.log_softmax(x, dim=1) . cnn_model = Net_d() cnn_model . Net( (cnn_layers): Sequential( (0): Conv2d(1, 4, kernel_size=(5, 5), stride=(1, 1)) (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU() (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (4): Conv2d(4, 4, kernel_size=(5, 5), stride=(1, 1)) (5): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (6): ReLU() (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) ) (linear_layers): Sequential( (0): Linear(in_features=64, out_features=10, bias=True) ) ) . cnn_criterion = nn.NLLLoss() cnn_optimizer = optim.SGD(cnn_model.parameters(), lr=0.001, momentum=0.9) epochs = 5 for e in range (epochs): for images, labels in train_data_loader: cnn_optimizer.zero_grad() # Forward. log_prob = cnn_model(images) loss = cnn_criterion(log_prob, labels) # Backward. loss.backward() # Optimize. cnn_optimizer.step() . correct_count = 0 count = 0 for data in test_data_loader: # 32 images and labels. images, labels = data # Get the predictions. # 32 outputs with log probabilities of 10 each for each of the 10 digits. with torch.no_grad(): outputs = cnn_model(images) # torch.max - with dim=1 (column) results in max of the probablilities for each of 32 images. It returns 2 values - max probabliltiy and max index, we are interested in the max index. _, is used to ignore the first set of output. _, predicted = torch.max(outputs.data, 1) # Get the number of images - 32 in each batch except for the last batch. count += labels.size(0) # Get the number of correct guesses in this batch. correct_count += (predicted == labels).sum().item() . accuracy = (correct_count/count) * 100 print(accuracy) . 97.92999999999999 . Dropout did not work well for our CNN. Why? . Using this CNN class, we got an accuracy of 81.69. Dropouts are not always effective, they are more effective when the training data - some of the reasons are using dropouts as the last step in NN gives the model no means to correct itself, when the network is small compared to the training data size, when there are not enough epochs to give reach convergence are all cited as reasons for this. . Other reasons CNN particularly does not take to droput has been observed as high level of correlation between activations and use of max pooling to reduce the number of parameters. . StackExchange KDNuggets . Batch Normalization . When a model is made of tens of layers, and data is fed in batches, the weight inputs a a layer get adjusted after every batch, which causes the model constantly readjust its weights and take longer to converge. This is called internal covariate shift. To counteract this, the learning rates need to be reduced or the initial parameters must be selected with care. This also means higher epochs to achieve a good model convergence. . Batch normalization is technique where the input to a layer is normalised such than mean is 0 and standard deviation of 1, which calms the constant shift in weights and helps achieve convergence faster. This also allows us to get rid of dropout layers. . [MachineCurve]https://www.machinecurve.com(/index.php/2020/01/14/what-is-batch-normalization-for-training-neural-networks/) MachineLearningMastery AIWorkBox OrignalPaper . class Net_b(nn.Module): # Constructor which first calls the base class constructor. def __init__(self): super(Net_b, self).__init__() self.cnn_layers = Sequential( Conv2d(in_channels=1, out_channels=4, kernel_size=5), BatchNorm2d(num_features=4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), ReLU(), MaxPool2d(kernel_size=2), Conv2d(in_channels=4, out_channels=4, kernel_size=5), BatchNorm2d(num_features=4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), ReLU(), MaxPool2d(kernel_size=2), ) # Final fully connected layer. self.linear_layers = Sequential( # Input and output. Linear(4 * 4 * 4, 10) ) def forward(self, x): x = self.cnn_layers(x) x = x.view(-1, 4 * 4 * 4) x = self.linear_layers(x) return F.log_softmax(x, dim=1) . cnn_model = Net_b() cnn_model . Net_b( (cnn_layers): Sequential( (0): Conv2d(1, 4, kernel_size=(5, 5), stride=(1, 1)) (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU() (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (4): Conv2d(4, 4, kernel_size=(5, 5), stride=(1, 1)) (5): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (6): ReLU() (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) ) (linear_layers): Sequential( (0): Linear(in_features=64, out_features=10, bias=True) ) ) . accuracy = (correct_count/count) * 100 print(accuracy) . 97.63 . Conclusion . We learnt important concepts such a dropout and batch normalization and applied it to our CNN. Neither actually performed better than the original CNN. .",
            "url": "https://avsuja.github.io/ordinary-to-legendary/jupyter/pytorch/neuralnetwork/convolutionalneuralnetwork/2020/01/18/understanding-cnn.html",
            "relUrl": "/jupyter/pytorch/neuralnetwork/convolutionalneuralnetwork/2020/01/18/understanding-cnn.html",
            "date": " • Jan 18, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "I am a Data Scientist at Pearson. Check out my LinkedIn profile. .",
          "url": "https://avsuja.github.io/ordinary-to-legendary/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://avsuja.github.io/ordinary-to-legendary/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}